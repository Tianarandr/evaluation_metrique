{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f0ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[24.  0.  0.]\n",
      " [ 0. 26.  0.]\n",
      " [ 0.  1. 24.]] \n",
      "\n",
      "Precision par classe :\n",
      "[1.0, 0.9629629629629629, 1.0] \n",
      "\n",
      "Precision globale :\n",
      "0.9876543209876543 \n",
      "\n",
      "Rappel par classe :\n",
      "[1.0, 1.0, 0.96] \n",
      "\n",
      "Rappel globale :\n",
      "0.9866666666666667 \n",
      "\n",
      "F-mesure globale :\n",
      "0.9871602467900616 \n",
      "\n",
      "F-mesure par classe :\n",
      "[1.0, 0.9811320754716981, 0.9795918367346939] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#fonction sous Python qui permet de calculer la matrice de confusion √† partir de deux vecteurs ùë¶ et y_estime\n",
    "def confusion_matrix(actual, predicted):\n",
    "    classes       = np.unique(np.concatenate((actual,predicted)))\n",
    "    confusion_mtx = np.empty((len(classes),len(classes)))\n",
    "    for i,a in enumerate(classes):\n",
    "        for j,p in enumerate(classes):\n",
    "            confusion_mtx[i,j] = np.where((actual==a)*(predicted==p))[0].shape[0]\n",
    "    return confusion_mtx\n",
    "\n",
    "\n",
    "#2 une fonction qui calcule la pr√©cision par classe.\n",
    "def precision_par_classe(matrice_conf):\n",
    "    pre=[]\n",
    "    for i in range(len(matrice_conf)):\n",
    "        for j in range(len(matrice_conf)):\n",
    "            if i == j:\n",
    "                som_colone_predi = np.sum(matrice_conf[:,j])\n",
    "                prediction = matrice_conf[i,j]/som_colone_predi\n",
    "                pre.append(prediction)\n",
    "    return pre\n",
    "\n",
    "#2 une fonction qui calcule la pr√©cision globale.\n",
    "def precision_globale(matrice_conf):\n",
    "    pre_classe = precision_par_classe(matrice_conf)\n",
    "    pre_globale = sum(pre_classe)/len(pre_classe)\n",
    "    return pre_globale\n",
    "    \n",
    "\n",
    "#3 une fonction qui permet de calculer le rappel par classe\n",
    "def rappel_par_classe(matrice_conf):\n",
    "    rappel_list=[]\n",
    "    for i in range(len(matrice_conf)):\n",
    "        for j in range(len(matrice_conf)):\n",
    "            if i == j:\n",
    "                som_ligne_actu = np.sum(matrice_conf[j,:])\n",
    "                rappel = matrice_conf[i,j]/som_ligne_actu\n",
    "                rappel_list.append(rappel)\n",
    "    return rappel_list\n",
    "\n",
    "#3 une fonction qui permet de calculer le rappel globale\n",
    "def rappel_globale(matrice_conf):\n",
    "    rap_classe = rappel_par_classe(matrice_conf)\n",
    "    rap_globale = sum(rap_classe)/len(rap_classe)\n",
    "    return rap_globale\n",
    "    \n",
    "#4 une fonction pour calculer la F-mesure globale.\n",
    "def f_mesure_globale(matrice_conf):\n",
    "    precision = precision_globale(matrice_conf)\n",
    "    rappel = rappel_globale(matrice_conf)\n",
    "    return 2 * ((precision * rappel)/ (precision + rappel))\n",
    "\n",
    "\n",
    "#4 une fonction pour calculer la F-mesure par classe.    \n",
    "def f_mesure_classe(matrice_conf):\n",
    "    precision_classe = precision_par_classe(matrice_conf)\n",
    "    rappel_classe = rappel_par_classe(matrice_conf)\n",
    "    f_mesure = []\n",
    "    for j in range(len(precision_classe)):\n",
    "        f_mesure.append(2*((precision_classe[j]*rappel_classe[j])/(precision_classe[j]+rappel_classe[j])))\n",
    "    return f_mesure\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#lire fichier TP1.xlsx\n",
    "df = pd.read_excel('TP1.xlsx')\n",
    "y = list(df['y'])\n",
    "y_estime = list(df['y_estim√©'])\n",
    "\n",
    "#confusion matrix\n",
    "matrice_conf = confusion_matrix(y, y_estime)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(matrice_conf, '\\n')\n",
    "\n",
    "#precision par classe\n",
    "pre_classe=precision_par_classe(matrice_conf)\n",
    "print(\"Precision par classe :\")\n",
    "print(pre_classe, '\\n')\n",
    "\n",
    "#precision globale\n",
    "pre_globale=precision_globale(matrice_conf)\n",
    "print(\"Precision globale :\")\n",
    "print(pre_globale, '\\n')\n",
    "\n",
    "\n",
    "#rappel par classe\n",
    "rapl_classe=rappel_par_classe(matrice_conf)\n",
    "print(\"Rappel par classe :\")\n",
    "print(rapl_classe, '\\n')\n",
    "\n",
    "#rappel globale\n",
    "rapl_globale=rappel_globale(matrice_conf)\n",
    "print(\"Rappel globale :\")\n",
    "print(rapl_globale, '\\n')\n",
    "\n",
    "\n",
    "#f-mesure globale\n",
    "f_mesure_globale = f_mesure_globale(matrice_conf)\n",
    "print(\"F-mesure globale :\")\n",
    "print(f_mesure_globale, '\\n')\n",
    "\n",
    "#f-mesure par classe\n",
    "f_mesure_cl= f_mesure_classe(matrice_conf)\n",
    "print(\"F-mesure par classe :\")\n",
    "print(f_mesure_cl, '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4d359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdf5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
